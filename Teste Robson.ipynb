{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4970eb45-18cd-43d3-9483-8454fb9ed3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O bucket bucket-robson não existe e será criado.\n",
      "O bucket bucket-robson foi criado na região us-east-1.\n",
      "O banco de dados database_robson não existe.\n",
      "A tabela tabela_robson no banco de dados database_robson não existe e será criado.\n",
      "{'Table': {'Name': 'tabela_robson', 'DatabaseName': 'database_robson', 'CreateTime': datetime.datetime(2023, 10, 26, 1, 5, 52, tzinfo=tzlocal()), 'UpdateTime': datetime.datetime(2023, 10, 26, 1, 5, 52, tzinfo=tzlocal()), 'Retention': 0, 'StorageDescriptor': {'Columns': [{'Name': 'name', 'Type': 'string'}, {'Name': 'age', 'Type': 'int'}], 'Location': 's3://bucket-robson/databases/', 'InputFormat': 'org.apache.hadoop.mapred.TextInputFormat', 'OutputFormat': 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat', 'Compressed': False, 'NumberOfBuckets': -1, 'SerdeInfo': {'Name': 'tabela_robson', 'SerializationLibrary': 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe', 'Parameters': {}}, 'SortColumns': [], 'StoredAsSubDirectories': False}, 'TableType': 'EXTERNAL_TABLE', 'CreatedBy': 'arn:aws:iam::443904021488:root', 'IsRegisteredWithLakeFormation': False, 'CatalogId': '443904021488', 'VersionId': '0'}, 'ResponseMetadata': {'RequestId': '6e108664-040a-4c59-b61a-d810e3c80f5c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Oct 2023 01:05:52 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '855', 'connection': 'keep-alive', 'x-amzn-requestid': '6e108664-040a-4c59-b61a-d810e3c80f5c'}, 'RetryAttempts': 0}}"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Substitua pelos seus valores\n",
    "database_name = \"database_robson\"\n",
    "table_name = \"tabela_robson\"\n",
    "bucket_name = \"bucket-robson\"\n",
    "s3_path = f\"s3://{bucket_name}/databases/\"\n",
    "\n",
    "# Substitua pela região desejada (por exemplo, \"us-east-1\")\n",
    "region = \"us-east-1\"\n",
    "\n",
    "# Inicialize o cliente S3 com a região especificada\n",
    "s3 = boto3.client('s3', region_name=region)\n",
    "\n",
    "# Verifique se o bucket já existe\n",
    "try:\n",
    "    s3.head_bucket(Bucket=bucket_name)\n",
    "    print(f'O bucket {bucket_name} já existe.')\n",
    "except Exception as e:\n",
    "    if e.response['Error']['Code'] == '404':\n",
    "        print(f'O bucket {bucket_name} não existe e será criado.')\n",
    "        try:\n",
    "            s3.create_bucket(Bucket=bucket_name)\n",
    "            print(f'O bucket {bucket_name} foi criado na região {region}.')\n",
    "        except Exception as e:\n",
    "            print(f'Ocorreu um erro ao criar o bucket: {e}')\n",
    "    else:\n",
    "        print(f'Ocorreu um erro ao verificar o bucket: {e}')\n",
    "\n",
    "# Se o bucket não existir, crie-o\n",
    "\n",
    "\n",
    "# Inicialize o cliente AWS Glue\n",
    "glue = boto3.client('glue')\n",
    "\n",
    "# Verifique se o banco de dados já existe\n",
    "try:\n",
    "    response = glue.get_database(Name=database_name)\n",
    "    print(f'O banco de dados {database_name} já existe.')\n",
    "except glue.exceptions.EntityNotFoundException:\n",
    "    print(f'O banco de dados {database_name} não existe.')\n",
    "    # Crie o banco de dados\n",
    "    glue.create_database(DatabaseInput={'Name': database_name})\n",
    "except Exception as e:\n",
    "    print(f'Ocorreu um erro ao verificar o banco de dados: {e}')\n",
    "    \n",
    "\n",
    "# Defina o esquema da tabela\n",
    "table_input = {\n",
    "    'DatabaseName': database_name,\n",
    "    'TableInput': {\n",
    "        'Name': table_name,\n",
    "        'StorageDescriptor': {\n",
    "            'Columns': [\n",
    "                {'Name': 'Name', 'Type': 'string'},\n",
    "                {'Name': 'Age', 'Type': 'int'}\n",
    "            ],\n",
    "            'Location': s3_path,\n",
    "            'InputFormat': 'org.apache.hadoop.mapred.TextInputFormat',\n",
    "            'OutputFormat': 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',\n",
    "            'Compressed': False,\n",
    "            'NumberOfBuckets': -1,\n",
    "            'SerdeInfo': {\n",
    "                'Name': table_name,\n",
    "                'SerializationLibrary': 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',\n",
    "                'Parameters': {}\n",
    "            }\n",
    "        },\n",
    "        'TableType': 'EXTERNAL_TABLE'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Verifique se a tabela já existe\n",
    "try:\n",
    "    response = glue.get_table(DatabaseName=database_name, Name=table_name)\n",
    "    print(f'A tabela {table_name} no banco de dados {database_name} já existe.')\n",
    "except glue.exceptions.EntityNotFoundException:\n",
    "    print(f'A tabela {table_name} no banco de dados {database_name} não existe e será criado.')\n",
    "    # Crie a tabela\n",
    "    glue.create_table(**table_input)\n",
    "except Exception as e:\n",
    "    print(f'Ocorreu um erro ao verificar a tabela: {e}')\n",
    "\n",
    "# Se quiser, atualize o Data Catalog para reconhecer as novas tabelas\n",
    "glue.get_table(DatabaseName=database_name, Name=table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "124f6866-a09b-4feb-a965-49011f81b5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from awsglue.context import GlueContext\n",
    "\n",
    "# Inicialize o contexto Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "glueContext = GlueContext(spark)\n",
    "\n",
    "# Defina os dados e o esquema da tabela\n",
    "data = [(\"John Doe\", 28), (\"Jane Smith\", 32), (\"Jim Brown\", 45)]\n",
    "columns = [\"Name\", \"Age\"]\n",
    "\n",
    "# Crie um DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Escreva o DataFrame como um arquivo Parquet\n",
    "df.write.mode(\"overwrite\").parquet(path=\"s3://bucket-robson/databases/\")\n",
    "\n",
    "# Registre o DataFrame como uma tabela no AWS Glue Data Catalog\n",
    "df.write.format(\"parquet\").mode(\"overwrite\").option(\"path\", \"s3://bucket-robson/databases/\").saveAsTable(f\"{database_name}.{table_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "689c4af6-6f19-4988-ad99-fc4be61ebfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|      Name|Age|\n",
      "+----------+---+\n",
      "|  John Doe| 28|\n",
      "|Jane Smith| 32|\n",
      "| Jim Brown| 45|\n",
      "+----------+---+"
     ]
    }
   ],
   "source": [
    "# Execute uma consulta SQL para selecionar todos os dados da tabela\n",
    "df = spark.sql(f\"SELECT * FROM {database_name}.{table_name}\")\n",
    "\n",
    "# Mostre os dados\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d6382-430f-4d0e-b166-730937a2aa27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
